broker.id={{ broker_id }}
listeners=PLAINTEXT://:9092

# upgrade
#inter.broker.protocol.version=0.10.2
#log.message.format.version=0.10.2

num.partitions=8
default.replication.factor=2
message.max.bytes=20971520
max.partition.fetch.bytes=20971520

delete.topic.enable=true
auto.leader.rebalance.enable=true
controlled.shutdown.enable=true
unclean.leader.election.enable=true
 
# Replication configurations
num.replica.fetchers=4
replica.fetch.max.bytes=20971520
replica.fetch.wait.max.ms=1000
replica.high.watermark.checkpoint.interval.ms=5000
replica.socket.timeout.ms=30000
replica.socket.receive.buffer.bytes=65536
replica.lag.time.max.ms=10000

controller.socket.timeout.ms=30000
controller.message.queue.size=10

# Log configuration
log.dirs={{ kafka_data_dir }}
num.recovery.threads.per.data.dir=1
auto.create.topics.enable=true
log.segment.bytes=1073741824
log.retention.hours=168
log.retention.check.interval.ms=300000
log.roll.hours=72
log.cleaner.enable=false
log.index.interval.bytes=4096
log.index.size.max.bytes=10485760
log.flush.interval.ms=10000
log.flush.interval.messages=20000
log.flush.scheduler.interval.ms=2000
log.segment.bytes=1073741824

# ZK configuration
zookeeper.connect={{ zookeeper_servers }}
zookeeper.session.timeout.ms=30000
zookeeper.connection.timeout.ms=16000
zookeeper.sync.time.ms=2000

# Socket server configuration
num.io.threads=24
num.network.threads=24
socket.request.max.bytes=104857600
socket.receive.buffer.bytes=1048576
socket.send.buffer.bytes=1048576
queued.max.requests=200
fetch.purgatory.purge.interval.requests=100
producer.purgatory.purge.interval.requests=100
